import torch


'''
Markov model:
No hidden state. States can be observed directly, and there are two assumptions:
1. limited horizon assumption
      P(zt|z1,z2,...,zt-1)=P(zt|zt-1)
2. stationary process assumption
      P(zt=sj|zt-1=si)=P(z2=sj|z1=si)
The observations z1,z2,...,zt are results generated by a random process
  which generates one state from the state set S=(s1,s2,...s|S|). |S| means
  the size of state set `S`.

We mark the state at time `0` as s0, and s0 can be taken as the initial state, 
  and we need a transition matrix `A`, and `Mij` means the probability from 
  state si to state sj. For the existence of `s0`, `A` should has the size of
  (|S|+1)x(|S|+1). `z0` is just the `s0`.
An example of `A` is 
          s0  sunny   cloudy  rain
      s0  0   0.33    0.33    0.33
   sunny  0   0.8     0.1     0.1
  cloudy  0   0.2     0.6     0.2
    rain  0   0.1     0.2     0.7
REMARK:  sum of each row is 1
'''


def mm_predict(z, A):
    '''
    mm: markov model
    Predict the probability of a state sequence
        P(z)=\prod_{t=1}^T M_{zt-1,zt}
    For convenience, we make `s0` the index 0 of `A`, and
    make all valid states corresponding to the index 1
    and increased by 1 in the order, so all values of `z`
    should be in the range [1, |S|].

    @parameters:
    z: the state sequence. shape is (T,) or (N,T)
    A: transition matrix

    @return:
        the probability of the state sequence, (1,) or (N,)
    '''
    if z.ndim == 1:
        z = z.unsqueeze(0)  # convert to (1,T), where N = 1
    T = z.shape[1]

    # initialize p: the probability from `s0` to the first observation
    p = A[0, z[:,0]]        # (N,)
    for t in range(T-1):
        p *= A[z[:,t+1],z[:,t]]
    return p


def mm_train(z, S):
    '''
    Learn the transtion matrix given the observation sequence(s)

    For convenience, we make `s0` the index 0 of `A`, and
    make all valid states corresponding to the index 1
    and increased by 1 in the order, so all values of `z`
    should be in the range [1, |S|].

    NOTICE: Because this model is so simple, I have not
    considered batch-training.

    Recall that z is a matrix in space {1,...,S}^{N x T},

    A_{i,j} = (sum_{t,k} z_{t,k}=i & z_{t,k+1}=j) / (\sum_{t,k} z_{t,k}=i)

    @parameters:
    z: the observation sequence(s), (T,) or (N,T)
    S: a scalar variable. Size of the state set(except the initial state `s0`)

    @return:
    A: the transition matrix. (S+1)x(S+1)
    '''
    if z.ndim == 1:
        z = z.unsqueeze(0)
    N, T = z.shape

    z = torch.hstack(torch.zeros(N, dtype=torch.int16), z) # (N, T+1)
    z1 = z[:,:-1]       # (N, T)  the previous states
    z2 = z[:,1:]        # (N, T)  the next states

    # A: (S+1)x(S+1)
    b = torch.empty(S+1)    # (S+1, ), i: from state
    A = torch.empty(S+1,S+1)    # i: from state; j: to state
    for si in range(S+1):   # tranverse all state: 0, 1, 2, ... , S
        mask1 = z1 == si    # filter the previous states with si , (N, T)
        b[si] = torch.sum(mask1) # number of si, scalar
        for sj in range(S+1):
            mask2 = z2 == sj        # (N, T)
            A[si, sj] = torch.sum(mask1 & mask2)    # scalar
        
        if b[si] == 0:   # laplace smoothing
            # the row of matrix transited from state `si` is unknown
            # we use the equal probability model, i.e. all values of
            # this row is 1/S except the first value. 
            A[si, 0] = 0
            A[si, 1:] = 1
            b[si] = S
    b = b.view(-1, 1)
    return A / b


'''
Hidden markov model

the observation x, a hidden state z(which cannot be observed).

Besides the two assumptions used in markov model, a third assumption is used:
3. observation indepentent assumption
    P(xt|x1,x2,...,xT,z1,z2,...,zT) = P(xt|zt)=B_{zt,xt}

All observations come from the set V=(v1,v2,...,v|V|), and all (hidden) states
from the set S=(s1,s2,...,S|S|).

The state transition matrix is `A`. The emit matrix is `B`, and `B_{ij}` 
means the probability of emitting `vj` at the state `si`.

THREE problems:
I. (predict) probability of a given observation sequence
    P(x;A,B) = \sum_z P(x,z;A,B)

II. (decode) the most possible state sequence of a given observation sequence


III. (learn) given a set of observation sequences and their state squences,
    learn to get the transition matrix and emission matrix
'''

def _forward(alpha, A, B, x):
    '''
    forward propagation

    alpha: (1, S). A probability vector at time `t` with length of S, where
        S is the size of the state set
            alpha_i(t) = P(x1,x2,...,xt,zt=si;A,B)
        alpha_i(t) means the probability when propagating to time `t` and the
            state at `t` must be i.

        At time `t+1`, suppose the state is `j`, then 
        the iterating equation is:
            alpha_j(t+1) = \sum_i alpha_i(t) * A_{i,j} * B_{j, x_{t+1}}
        
    A: transition matrix, (S, S), (remove the start state `s0`)
    B: emission matrix (S, V)
    x: the observation at time `t+1`. (scalar)
    '''
    # alpha_{1j} := \sum_i alpha_{1i} * A_{ij}
    alpha = torch.mm(alpha, A)  # (1, S)
    # alpha_j := alpha_j * B_{j,xt}
    alpha = alpha * B[:,x].view(1,-1)   # (1, S)
    return alpha                       # (1, S)


def _backward(beta, A, B, x):
    '''
    backward propagation

    beta: (S, 1).
        beta_i(t) = P(xt+1,...,xT,zt=si;A,B)
    '''
    # beta_j := B_{j,xt+1} * beta_j
    beta = B[:,x].view(-1,1) * beta         # (S, 1)
    # beta_i := \sum_j A_{ij} * beta_{1j}
    beta = torch.mm(A, beta)                # (S, 1)
    return beta

def predict(x, A, B):
    '''
    Predict the probability of an observation sequence.

    @parameters:
        x: (T,), each value of x is in the range `[0, V)`   observation sequence
        A: transition matrix, (S+1, S+1)        # transition matrix
        B: emission matrix, (S, V)              # emision matrix

    @return:
        the probability, a scalar
    '''
    # def _backward():      # use the model method `_backward` instead.
    #     beta = torch.ones((S, 1), dtype=torch.float)
    #     for t in range(T-1, 0, -1):
    #         m = B[:,x[t]].unsqueeze(-1) * beta   # (S, 1)
    #         beta = torch.mm(AA, m)                  # (S, 1)
    #     return torch.dot(A[0,1:]*B[:,x[0]], beta[:,0])
        
    T = x.shape[0]
    S = A.shape[0] - 1
    AA = A[1:,1:]

    # ========================= forward =========================+
    # alpha(initial time, no observation)
    alpha = A[0,1:].unsqueeze(0)         # (1, S)
    for t in range(T):
        alpha = _forward(alpha, AA, B, x[t])
    return torch.sum(alpha)
    # ========================= forward =========================+


    # ========================= backward =========================
    # instead of `forward`, we can also use `backward`
    # beta(t=T)
    beta = torch.ones((S, 1), dtype=torch.float)
    for t in range(T-1, 0, -1):
        # calc for T-1, T-2, ... , 1
        beta = _backward(beta, AA, B, x[t])
    beta = A[0,1:] * B[:,x[0]] * beta.view(-1)
    return torch.sum(beta)
    # ========================= backward =========================
    

def decode(x, A, B):
    '''
    Decode an observation sequence to get the state sequence.

    The state sequence with a max probability. Use dynamic programming.

    define: delta_i(t): max_{z1,...,z_{t-1}} P(x1,...,xt, z1,...,zt=i)
    then iterating equation:
        delta_j(t+1) = max_{z1,...,zt} P(x1,...,x_{t+1}, z1,...,z_{t+1}=j)
                     = max_{z1,...,zt} P(x1,...,xt,z1,...,zt) * A_{zt,j} * B_{j,x_{t+1}}
                     = max_i max_{z1,...,z_{t-1}} P(x1,...,xt,z1,...,zt=i) * A_{zt,j} * B_{j,x_{t+1}}
                     = max_i delta_i(t) * A_{i,j} * B_{j,x_{t+1}}
    the initial condition:
        delta_i(t=1) = max_{z0} P(x1, z1=i) = A_{0,i} * B_{i,x1}


    @parameters:
        x: an observation sequence, (T,)
        A: transition matrix, (S+1, S+1)
        B: emission matrix, (S, V)
    
    @return:
        the most possible state sequence, (T,)  
        label indices, in the range [1, S] (0 is the index of s0)
    '''
    T = x.shape[0]
    S = A.shape[0] - 1          # state set size, except the s0
    P = torch.empty(T-1, S)     # store all full path

    # initialation: delta(t=1)
    # delta_i(t=1) = P(x_1,z_1=s_i) = A_{0i} * B_{i,x_1}
    delta = A[0,1:] * B[:,x[0]]     # (S, )
    delta = delta.view(-1, 1)       # convert to (S, 1)
    AA = A[1:,1:]                   # (S, S)
    for t in range(1, T):   # delta: t=2,3,...,T
        # delta_{ij} := delta_{i,1} * A_{ij} * B_{j,xt}
        delta = (delta * AA) * B[:,x[t]].view(1,-1)     # (S, S)
        delta, indices = torch.max(delta, dim=0)        # (S, )
        delta = delta.view(-1, 1)                       # (S,) -> (S, 1)

        # indices, (S,), each value is in the range [0, S)
        # store the index `i`` of state from which the next state `j` 
        #   has the largest delta
        # indices is a vector: indices[j] = i
        P[t-1] = indices
    
    # the last state of the most possible state sequence is:
    #       argmax_i delta(T)
    i = torch.argmax(delta[:,0])
    path = torch.zeros(T, dtype=torch.int16)
    path[-1] = i
    for t in range(T-2, -1, -1):
        path[t] = P[t, path[t+1]]
    # +1 -> `s0` has the index 0, while all other states' indices are increased by 1.
    return path + 1


def train(x, A, B):
    '''
    x: (T,), for different x, the length T can be different too.
    '''
    T = x.shape[0]
    # A = torch.zeros((S+1,S+1), dtype=torch.float)
    # B = torch.zeros((S, V), dtype=torch.float).fill_(1/V)
    # A[:,1:] = 1/S

    alpha = torch.empty(())
